import cv2
from google.colab.patches import cv2_imshow
import numpy as np
# Load the pre-trained MobileNet SSD model
net = cv2.dnn.readNetFromCaffe('/content/MobileNetSSD_deploy.prototxt','/content/MobileNetSSD_deploy.caffemodel')

# Specify the input video path
input_video_path = r'/content/y2mate.is - Raw Video The President Takes a Surprise Walk-gZR1CvSQntE-480pp-1703391485.mp4'

# Open the video file
cap = cv2.VideoCapture(input_video_path)

# Get video properties
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# Define the codec and create VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'XVID')
output_video_path = 'output_video_ssd.2.avi'
out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

while cap.isOpened():
    ret, frame = cap.read()

    if not ret:
        break

    # Convert the frame to a blob
    blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)

    # Set the input to the neural network
    net.setInput(blob)

    # Forward pass and get detection result
    detections = net.forward()

    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]

        if confidence > 0.2:  # Adjust confidence threshold as needed
            # Get the coordinates of the bounding box
            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])
            (startX, startY, endX, endY) = box.astype("int")

            # Draw the bounding box and label
            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)

    # Save the frame to the output video
    out.write(frame)

    # Display the frame with human detection
    #cv2.imshow('Human Detection', frame)

    # Break the loop if 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release video capture and writer objects
cap.release()
out.release()
cv2.destroyAllWindows()
